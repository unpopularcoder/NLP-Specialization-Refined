{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wmf07eJE8p9r"
   },
   "source": [
    "# Assignment 4: Chatbot\n",
    "\n",
    "<img src = \"cbot.jpg\" height=\"400\" width=\"400\"> \n",
    "\n",
    "Welcome to the last assignment of Course 4. Before you get started, we want to congratulate you on getting here. It is your 16th programming assignment in this Specialization and we are very proud of you! In this assignment, you are going to use the [Reformer](https://arxiv.org/abs/2001.04451), also known as the efficient Transformer, to generate a dialogue between two bots. You will feed conversations to your model and it will learn how to understand the context of each one. Not only will it learn how to answer questions but it will also know how to ask questions if it needs more info. For example, after a customer asks for a train ticket, the chatbot can ask what time the said customer wants to leave. You can use this concept to automate call centers, hotel receptions, personal trainers, or any type of customer service. By completing this assignment, you will:\n",
    "\n",
    "* Understand how the Reformer works\n",
    "* Explore the [MultiWoz](https://arxiv.org/abs/1810.00278) dataset\n",
    "* Process the data to feed it into the model\n",
    "* Train your model\n",
    "* Generate a dialogue by feeding a question to the model\n",
    "\n",
    "\n",
    "## Outline\n",
    "- [Part 1:   Exploring the MultiWoz dataset](#1)\n",
    "\t- [Exercise 01](#ex01)\n",
    "- [Part 2:   Processing the data for Reformer inputs](#2)\n",
    "    - [2.1   Tokenizing, batching with bucketing](#2.1)\n",
    "- [Part 3:   Reversible layers](#3)\n",
    "\t- [Exercise 02](#ex02)\n",
    "\t- [Exercise 03](#ex03)\n",
    "    - [3.1   Reversible layers and randomness](#3.1)\n",
    "- [Part 4:   ReformerLM Training](#4)\n",
    "\t- [Exercise 04](#ex04)\n",
    "\t- [Exercise 05](#ex05)\n",
    "- [Part 5:   Decode from a pretrained model](#5)\n",
    "\t- [Exercise 06](#ex06)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# Part 1:   Exploring the MultiWoz dataset\n",
    "\n",
    "You will start by exploring the MultiWoz dataset. The dataset you are about to use has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains. In this section, you will load and explore this dataset, as well as develop a function to extract the dialogues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the modules we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "aV4zpTnSVFIp",
    "outputId": "e3a85dd1-e375-4636-ea62-b9b403f0952a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n",
      "trax                     1.3.4\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "import trax   \n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "!pip list | grep trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also declare some constants we will be using in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename of the MultiWOZ dialogue dataset\n",
    "DATA_FILE = 'data.json'\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# dictionary where we will load the dialogue dataset\n",
    "DIALOGUE_DB = {}\n",
    "\n",
    "# vocabulary filename\n",
    "VOCAB_FILE = 'en_32k.subword'\n",
    "\n",
    "# vocabulary file directory\n",
    "VOCAB_DIR = 'data/vocabs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the MultiWOZ 2.1 dataset. We have already provided it for you in your workspace. It is in JSON format so we should load it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "K58I5vFB7GlP",
    "outputId": "3d086ea4-7898-4870-b52f-f362cb02e118"
   },
   "outputs": [],
   "source": [
    "# help function to load a JSON file\n",
    "def load_json(directory, file):\n",
    "    with open(f'{directory}/{file}') as file: \n",
    "        db = json.load(file)\n",
    "    return db\n",
    "\n",
    "# load the dialogue data set into our dictionary\n",
    "DIALOGUE_DB = load_json(DATA_DIR, DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many dialogues we have in the dictionary. 1 key-value pair is one dialogue so we can just get the dictionary's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "VGBnUfEk8p9x",
    "outputId": "4b364506-1088-4f00-be0c-4fefa892dc4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dialogues is: 10438\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of dialogues is: {len(DIALOGUE_DB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dialogues are composed of multiple files and the filenames are used as keys in our dictionary. Those with multi-domain dialogues have \"MUL\" in their filenames while single domain dialogues have either \"SNG\" or \"WOZ\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json', 'SNG0073.json', 'SNG01445.json', 'MUL2105.json']\n"
     ]
    }
   ],
   "source": [
    "# print 7 keys from the dataset to see the filenames\n",
    "print(list(DIALOGUE_DB.keys())[0:7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pE6wiMUS8p91"
   },
   "source": [
    "As you can see from the cells above, there are 10,438 conversations, each in its own file.  You will train your model on all those conversations. Each file is also loaded into a dictionary and each has two keys which are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5KYeQLnG8p96",
    "outputId": "b22f570d-a7b0-4b92-ba68-0b7236e61051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['goal', 'log'])\n"
     ]
    }
   ],
   "source": [
    "# get keys of the fifth file in the list above\n",
    "print(DIALOGUE_DB['SNG0073.json'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-gj5aqF8p9_"
   },
   "source": [
    "The `goal` also points to a dictionary and it contains several keys pertaining to the objectives of the conversation. For example below, we can see that the conversation will be about booking a taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "PPPWwQ2s8p9_",
    "outputId": "7e8efa2d-821a-44c8-902d-2c722baf5b4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taxi': {'info': {'leaveAt': '17:15',\n",
       "   'destination': 'pizza hut fen ditton',\n",
       "   'departure': \"saint john's college\"},\n",
       "  'reqt': ['car type', 'phone'],\n",
       "  'fail_info': {}},\n",
       " 'police': {},\n",
       " 'hospital': {},\n",
       " 'hotel': {},\n",
       " 'attraction': {},\n",
       " 'train': {},\n",
       " 'message': [\"You want to book a <span class='emphasis'>taxi</span>. The taxi should go to <span class='emphasis'>pizza hut fen ditton</span> and should depart from <span class='emphasis'>saint john's college</span>\",\n",
       "  \"The taxi should <span class='emphasis'>leave after 17:15</span>\",\n",
       "  \"Make sure you get <span class='emphasis'>car type</span> and <span class='emphasis'>contact number</span>\"],\n",
       " 'restaurant': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIALOGUE_DB['SNG0073.json']['goal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4N8RtWu8p-C"
   },
   "source": [
    "The `log` on the other hand contains the dialog. It is a list of dictionaries and each element of this list contains several descriptions as well. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.\",\n",
       " 'metadata': {},\n",
       " 'dialog_act': {'Taxi-Inform': [['Dest', 'pizza hut fen ditton'],\n",
       "   ['Depart', \"saint john 's college\"]]},\n",
       " 'span_info': [['Taxi-Inform', 'Dest', 'pizza hut fen ditton', 11, 14],\n",
       "  ['Taxi-Inform', 'Depart', \"saint john 's college\", 6, 9]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first element of the log list\n",
    "DIALOGUE_DB['SNG0073.json']['log'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we are only interested in the conversation which is in the `text` field.\n",
    "The conversation goes back and forth between two persons. Let's call them 'Person 1' and 'Person 2'. This implies that\n",
    "data['SNG0073.json']['log'][0]['text'] is 'Person 1' and\n",
    "data['SNG0073.json']['log'][1]['text'] is 'Person 2' and so on. The even offsets are 'Person 1' and the odd offsets are 'Person 2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.\n",
      " Person 2:  What time do you want to leave and what time do you want to arrive by?\n"
     ]
    }
   ],
   "source": [
    "print(' Person 1: ', DIALOGUE_DB['SNG0073.json']['log'][0]['text'])\n",
    "print(' Person 2: ',DIALOGUE_DB['SNG0073.json']['log'][1]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 01\n",
    "\n",
    "You will now implement the `get_conversation()` function that will extract the conversations from the dataset's file.\n",
    "\n",
    "**Instructions:** Implement a function to extract conversations from the input file.   \n",
    "As described above, the conversation is in the `text` field in each of the elements in the `log` list of the file. If the log list has `x` number of elements, then the function will get the `text` entries of each of those elements. Your function should return the conversation, prepending each field with either ' Person 1: ' if 'x' is even or ' Person 2: ' if 'x' is odd. You can use the Python modulus operator '%' to help select the even/odd entries. Important note: Do not print a newline character (i.e. `\\n`) when generating the string. For example, in the code cell above, your function should output something like:\n",
    "\n",
    "```\n",
    " Person 1: I would like a taxi from Saint John's college to Pizza Hut Fen Ditton. Person 2: What time do you want to leave and what time do you want to arrive by?\n",
    "```\n",
    "\n",
    "and **not**:\n",
    "\n",
    "```\n",
    " Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.\n",
    " Person 2:  What time do you want to leave and what time do you want to arrive by?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: get_conversation\n",
    "def get_conversation(file, data_db):\n",
    "    '''\n",
    "    Args:\n",
    "        file (string): filename of the dialogue file saved as json\n",
    "        data_db (dict): dialogue database\n",
    "    \n",
    "    Returns:\n",
    "        string: A string containing the 'text' fields of  data[file]['log'][x]\n",
    "    '''\n",
    "    \n",
    "    # initialize empty string\n",
    "    result = ''\n",
    "    \n",
    "    # get length of file's log list\n",
    "    len_msg_log = len(data_db[file]['log'])\n",
    "    \n",
    "    # set the delimiter strings\n",
    "    delimiter_1 = ' Person 1: '\n",
    "    delimiter_2 = ' Person 2: '\n",
    "    \n",
    "    # loop over the file's log list\n",
    "    for i in range(len_msg_log):\n",
    "        \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    \n",
    "        # get i'th element of file log list\n",
    "        cur_log = data_db[file]['log'][i]\n",
    "        \n",
    "        # check if i is even\n",
    "        if i%2 == 0:                   \n",
    "            # append the 1st delimiter string\n",
    "            result += delimiter_1\n",
    "        else: \n",
    "            # append the 2nd delimiter string\n",
    "            result += delimiter_2\n",
    "        \n",
    "        # append the message text from the log\n",
    "        result += cur_log['text']\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# BEGIN UNIT TEST\n",
    "import w4_unittest\n",
    "w4_unittest.test_get_conversation(get_conversation)\n",
    "# END UNIT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ugvx0noP8p-G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.\n",
      "Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.\n"
     ]
    }
   ],
   "source": [
    "file = 'SNG01856.json'\n",
    "conversation = get_conversation(file, DIALOGUE_DB)\n",
    "\n",
    "# print raw output\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Result:**\n",
    "```\n",
    "Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.\n",
    "Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a utility pretty print function just so we can visually follow the conversation more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPerson 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel \u001b[0m\n",
      "\u001b[32mPerson 2: Okay, do you have a specific area you want to stay in? \u001b[0m\n",
      "\u001b[31mPerson 1: no, i just need to make sure it's cheap. oh, and i need parking \u001b[0m\n",
      "\u001b[32mPerson 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? \u001b[0m\n",
      "\u001b[31mPerson 1: Yes, please. 6 people 3 nights starting on tuesday. \u001b[0m\n",
      "\u001b[32mPerson 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? \u001b[0m\n",
      "\u001b[31mPerson 1: how about only 2 nights. \u001b[0m\n",
      "\u001b[32mPerson 2: Booking was successful.\n",
      "Reference number is : 7GAWK763. Anything else I can do for you? \u001b[0m\n",
      "\u001b[31mPerson 1: No, that will be all. Good bye. \u001b[0m\n",
      "\u001b[32mPerson 2: Thank you for using our services.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def print_conversation(conversation):\n",
    "    \n",
    "    delimiter_1 = 'Person 1: '\n",
    "    delimiter_2 = 'Person 2: '\n",
    "    \n",
    "    split_list_d1 = conversation.split(delimiter_1)\n",
    "    \n",
    "    for sublist in split_list_d1[1:]:\n",
    "        split_list_d2 = sublist.split(delimiter_2)\n",
    "        print(colored(f'Person 1: {split_list_d2[0]}', 'red'))\n",
    "        \n",
    "        if len(split_list_d2) > 1:\n",
    "            print(colored(f'Person 2: {split_list_d2[1]}', 'green'))\n",
    "\n",
    "            \n",
    "print_conversation(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzg21Kgc8p-K"
   },
   "source": [
    "For this assignment, we will just use the outputs of the calls to `get_conversation` to train the model. But just to expound, there are also other information in the MultiWoz dataset that can be useful in other contexts. Each element of the log list has more information about it. For example, above, if you were to look at the other fields for the following, \"am looking for a place to stay that has cheap price range it should be in a type of hotel\", you will get the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Rs2R8q1d8p-K",
    "outputId": "8a2f4e3f-4516-449f-9648-a5970707cfc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel',\n",
       " 'metadata': {},\n",
       " 'dialog_act': {'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]},\n",
       " 'span_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],\n",
       "  ['Hotel-Inform', 'Price', 'cheap', 10, 10]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIALOGUE_DB['SNG01856.json']['log'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nf0AAmxy8p-N"
   },
   "source": [
    "The dataset also comes with hotel, hospital, taxi, train, police, and restaurant databases. For example, in case you need to call a doctor, or a hotel, or a taxi, this will allow you to automate the entire conversation. Take a look at the files accompanying the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "HQmYUcsi8p-O",
    "outputId": "5730c55f-63da-42a8-935e-6eeb17f6f791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east', 'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name': 'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088', 'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the attractions file\n",
    "attraction_file = open('data/attraction_db.json')\n",
    "attractions = json.load(attraction_file)\n",
    "print(attractions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I5kTg4uX8p-R",
    "outputId": "3dacc4ff-4f05-4ae6-d099-33d1b3a6fa2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'department': 'neurosciences critical care unit', 'id': 0, 'phone': '01223216297'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the hospital file\n",
    "hospital_file = open('data/hospital_db.json')\n",
    "hospitals = json.load(hospital_file)\n",
    "print(hospitals[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "B5knaAEc8p-U",
    "outputId": "ee0110c2-b2c2-4584-bd42-21f75109a579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking': 'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': {'double': '70', 'family': '90', 'single': '50'}, 'pricerange': 'moderate', 'stars': '4', 'takesbookings': 'yes', 'type': 'guesthouse'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the hotel file\n",
    "hotel_file = open('data/hotel_db.json')\n",
    "hotels = json.load(hotel_file)\n",
    "print(hotels[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t-Rk01Mv8p-a",
    "outputId": "8977e17e-2fc3-4073-abb8-fcf5cef3cfaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0, 'phone': '01223358966'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the police file\n",
    "police_file = open('data/police_db.json')\n",
    "police = json.load(police_file)\n",
    "print(police[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "u-G9pD8g8p-d",
    "outputId": "1dba6598-b9b6-4fc8-91d2-f844b98e45fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian', 'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants nationwide offering convenience pizzas pasta and salads to eat in or take away', 'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone': '01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type': 'restaurant'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of a restuarant file\n",
    "restaurant_file = open('data/restaurant_db.json')\n",
    "restaurants = json.load(restaurant_file)\n",
    "print(restaurants[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9eAKw4R8p-g"
   },
   "source": [
    "For more information about the multiwoz 2.1 data set, please run the cell below to read the `ReadMe.txt` file. Feel free to open any other file to explore it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "2H8pB_yI8p-g",
    "outputId": "aa039a49-3ed3-4f4d-fa4f-c2619de3dc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################\n",
      "#####################################################\n",
      "#  Copyright Cambridge Dialogue Systems Group, 2018 #\n",
      "#####################################################\n",
      "#####################################################\n",
      "\n",
      "Dataset contains the following files:\n",
      "1. data.json: the woz dialogue dataset, which contains the conversation  users and wizards, as well as a set of coarse labels for each user turn. This file contains both system and user dialogue acts annotated at the turn level. Files with multi-domain dialogues have \"MUL\" in